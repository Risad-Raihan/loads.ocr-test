{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Testing dots.ocr for Bengali OCR\n\nThis notebook tests the [rednote-hilab/dots.ocr](https://huggingface.co/rednote-hilab/dots.ocr) model for Bengali language OCR capabilities.\n\ndots.ocr is a powerful 3.04B parameter multilingual document parser that unifies layout detection and content recognition within a single vision-language model.\n","metadata":{}},{"cell_type":"code","source":"# Install required dependencies\n%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n%pip install transformers>=4.37.0\n%pip install qwen-vl-utils\n%pip install accelerate\n%pip install pillow\n%pip install requests\n%pip install matplotlib\n%pip install numpy\n%pip install opencv-python\n\n# Try to install flash-attention (may fail on some systems)\ntry:\n    import subprocess\n    import sys\n    result = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"flash-attn\", \"--no-build-isolation\"], \n                          capture_output=True, text=True)\n    if result.returncode == 0:\n        print(\"Flash attention installed successfully\")\n    else:\n        print(\"Flash attention installation failed, continuing without it...\")\nexcept Exception as e:\n    print(f\"Flash attention installation error: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:59:43.371317Z","iopub.execute_input":"2025-08-06T10:59:43.371618Z","iopub.status.idle":"2025-08-06T11:00:13.461438Z","shell.execute_reply.started":"2025-08-06T10:59:43.371583Z","shell.execute_reply":"2025-08-06T11:00:13.460594Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Looking in indexes: https://download.pytorch.org/whl/cu121\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu121)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: qwen-vl-utils in /usr/local/lib/python3.11/dist-packages (0.0.11)\nRequirement already satisfied: av in /usr/local/lib/python3.11/dist-packages (from qwen-vl-utils) (15.0.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from qwen-vl-utils) (25.0)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from qwen-vl-utils) (11.2.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from qwen-vl-utils) (2.32.4)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->qwen-vl-utils) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->qwen-vl-utils) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->qwen-vl-utils) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->qwen-vl-utils) (2025.6.15)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu121)\nRequirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.33.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.5.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate) (12.5.82)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.6.15)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.4)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->matplotlib) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20->matplotlib) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\nRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\nFlash attention installed successfully\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Import required libraries\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoProcessor\nfrom qwen_vl_utils import process_vision_info\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport json\nimport requests\nfrom io import BytesIO\nimport os\nfrom huggingface_hub import login\nimport gc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T11:00:13.463212Z","iopub.execute_input":"2025-08-06T11:00:13.463476Z","iopub.status.idle":"2025-08-06T11:00:21.542103Z","shell.execute_reply.started":"2025-08-06T11:00:13.463452Z","shell.execute_reply":"2025-08-06T11:00:21.541309Z"}},"outputs":[{"name":"stderr","text":"2025-08-06 11:00:18.427908: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754478018.451585     224 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754478018.458708     224 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Model Loading and Setup","metadata":{}},{"cell_type":"code","source":"# Check GPU availability\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {device}\")\n\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"CUDA Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T11:00:21.685773Z","iopub.execute_input":"2025-08-06T11:00:21.686041Z","iopub.status.idle":"2025-08-06T11:00:21.771780Z","shell.execute_reply.started":"2025-08-06T11:00:21.686017Z","shell.execute_reply":"2025-08-06T11:00:21.771206Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nGPU: Tesla T4\nCUDA Memory: 14.7 GB\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Load the model and processor\nmodel_id = \"rednote-hilab/dots.ocr\"\n\nprint(\"Loading processor...\")\nprocessor = AutoProcessor.from_pretrained(\n    model_id, \n    trust_remote_code=True,\n    token=HF_TOKEN  # Updated parameter name\n)\n\nprint(\"Loading model...\")\n# Load model with optimizations for Kaggle environment\ntry:\n    # Try with flash attention first\n    model = AutoModelForCausalLM.from_pretrained(\n        model_id,\n        torch_dtype=torch.bfloat16,  # Use bfloat16 for memory efficiency\n        device_map=\"auto\",  # Automatically distribute across available devices\n        trust_remote_code=True,\n        token=HF_TOKEN,  # Updated parameter name\n        low_cpu_mem_usage=True,  # Reduce CPU memory usage during loading\n        attn_implementation=\"flash_attention_2\"  # Use flash attention for efficiency\n    )\n    print(\"Model loaded with flash attention!\")\nexcept Exception as e:\n    print(f\"Flash attention failed: {e}\")\n    print(\"Loading model without flash attention...\")\n    # Fallback without flash attention\n    model = AutoModelForCausalLM.from_pretrained(\n        model_id,\n        torch_dtype=torch.bfloat16,\n        device_map=\"auto\",\n        trust_remote_code=True,\n        token=HF_TOKEN,\n        low_cpu_mem_usage=True\n    )\n    print(\"Model loaded without flash attention!\")\n\nprint(f\"Model device: {model.device}\")\nprint(f\"Model dtype: {model.dtype}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T11:00:21.773113Z","iopub.execute_input":"2025-08-06T11:00:21.773354Z","iopub.status.idle":"2025-08-06T11:00:23.506116Z","shell.execute_reply.started":"2025-08-06T11:00:21.773336Z","shell.execute_reply":"2025-08-06T11:00:23.505182Z"}},"outputs":[{"name":"stdout","text":"Loading processor...\nLoading model...\nFlash attention failed: No module named 'transformers_modules.rednote-hilab.dots'\nLoading model without flash attention...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_224/2068054528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Try with flash attention first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0mclass_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m             model_class = get_class_from_dynamic_module(\n\u001b[0m\u001b[1;32m    559\u001b[0m                 \u001b[0mclass_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_revision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcode_revision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/dynamic_module_utils.py\u001b[0m in \u001b[0;36mget_class_from_dynamic_module\u001b[0;34m(class_reference, pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, code_revision, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_class_in_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_reload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/dynamic_module_utils.py\u001b[0m in \u001b[0;36mget_class_in_module\u001b[0;34m(class_name, module_path, force_reload)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__transformers_module_hash__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmodule_hash\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0mmodule_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__transformers_module_hash__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_hash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","\u001b[0;32m~/.cache/huggingface/modules/transformers_modules/rednote-hilab/dots.ocr/42f41787f2475c0894d75a9e30e49cc1a6df519f/modeling_dots_ocr.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfiguration_dots\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDotsVisionConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDotsOCRConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodeling_dots_vision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDotsVisionTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers_modules.rednote-hilab.dots'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_224/2068054528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading model without flash attention...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Fallback without flash attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_remote_code\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0mclass_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m             model_class = get_class_from_dynamic_module(\n\u001b[0m\u001b[1;32m    559\u001b[0m                 \u001b[0mclass_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_revision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcode_revision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/dynamic_module_utils.py\u001b[0m in \u001b[0;36mget_class_from_dynamic_module\u001b[0;34m(class_reference, pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, code_revision, **kwargs)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mrepo_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_class_in_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_reload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/dynamic_module_utils.py\u001b[0m in \u001b[0;36mget_class_in_module\u001b[0;34m(class_name, module_path, force_reload)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;31m# reload in both cases, unless the module is already imported and the hash hits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__transformers_module_hash__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmodule_hash\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0mmodule_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__transformers_module_hash__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_hash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","\u001b[0;32m~/.cache/huggingface/modules/transformers_modules/rednote-hilab/dots.ocr/42f41787f2475c0894d75a9e30e49cc1a6df519f/modeling_dots_ocr.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfiguration_dots\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDotsVisionConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDotsOCRConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodeling_dots_vision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDotsVisionTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers_modules.rednote-hilab.dots'"],"ename":"ModuleNotFoundError","evalue":"No module named 'transformers_modules.rednote-hilab.dots'","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"import os\nimport sys\nimport shutil\nfrom pathlib import Path\n\ndef fix_dots_ocr_modules():\n    \"\"\"\n    Fix the transformers_modules issue for dots.ocr\n    \"\"\"\n    print(\"Attempting to fix dots.ocr module loading...\")\n    \n    # Get the transformers cache directory\n    from transformers.utils import TRANSFORMERS_CACHE\n    cache_dir = Path(TRANSFORMERS_CACHE)\n    \n    # Look for the dots.ocr modules\n    modules_dir = cache_dir / \"modules\" / \"transformers_modules\" / \"rednote-hilab\" / \"dots.ocr\"\n    \n    if modules_dir.exists():\n        print(f\"Found dots.ocr modules at: {modules_dir}\")\n        \n        # List all subdirectories (different versions/commits)\n        for version_dir in modules_dir.iterdir():\n            if version_dir.is_dir():\n                print(f\"Found version: {version_dir.name}\")\n                \n                # Add the directory to Python path\n                if str(version_dir) not in sys.path:\n                    sys.path.insert(0, str(version_dir))\n                    print(f\"Added {version_dir} to Python path\")\n                \n                # Try to create the missing module structure\n                try:\n                    init_file = version_dir / \"__init__.py\"\n                    if not init_file.exists():\n                        init_file.touch()\n                        print(f\"Created __init__.py in {version_dir}\")\n                except Exception as e:\n                    print(f\"Could not create __init__.py: {e}\")\n    else:\n        print(\"dots.ocr modules not found in cache\")\n    \n    return modules_dir.exists()\n\n# Try to fix the module issue\nif fix_dots_ocr_modules():\n    print(\"Module fix attempted. Trying to load model...\")\nelse:\n    print(\"Could not find cached modules. Model may need to be downloaded first.\")\n\n# Clear any problematic cached imports\nmodules_to_clear = [k for k in sys.modules.keys() if 'transformers_modules' in k or 'dots' in k]\nfor module in modules_to_clear:\n    del sys.modules[module]\n    \nprint(f\"Cleared {len(modules_to_clear)} cached modules\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T11:01:21.861115Z","iopub.execute_input":"2025-08-06T11:01:21.861883Z","iopub.status.idle":"2025-08-06T11:01:21.871286Z","shell.execute_reply.started":"2025-08-06T11:01:21.861856Z","shell.execute_reply":"2025-08-06T11:01:21.870583Z"}},"outputs":[{"name":"stdout","text":"Attempting to fix dots.ocr module loading...\ndots.ocr modules not found in cache\nCould not find cached modules. Model may need to be downloaded first.\nCleared 4 cached modules\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# COMPLETE FIX for dots.ocr module loading issue\nimport sys\nimport os\nfrom pathlib import Path\nfrom transformers.utils import TRANSFORMERS_CACHE\n\ndef fix_dots_ocr_imports():\n    \"\"\"\n    Fix the broken relative imports in dots.ocr custom modules\n    \"\"\"\n    print(\"Fixing dots.ocr module imports...\")\n    \n    # Find the dots.ocr module directory\n    cache_dir = Path(TRANSFORMERS_CACHE)\n    dots_module_dir = cache_dir / \"modules\" / \"transformers_modules\" / \"rednote-hilab\" / \"dots.ocr\"\n    \n    if not dots_module_dir.exists():\n        print(\"dots.ocr module directory not found\")\n        return False\n    \n    # Find the specific version directory\n    version_dirs = [d for d in dots_module_dir.iterdir() if d.is_dir()]\n    if not version_dirs:\n        print(\"No version directories found\")\n        return False\n    \n    version_dir = version_dirs[0]  # Use the first (and likely only) version\n    print(f\"Found version directory: {version_dir}\")\n    \n    # Add the version directory to Python path\n    if str(version_dir) not in sys.path:\n        sys.path.insert(0, str(version_dir))\n        print(f\"Added {version_dir} to Python path\")\n    \n    # Create proper __init__.py files\n    init_files = [\n        version_dir / \"__init__.py\",\n        version_dir.parent / \"__init__.py\",\n        version_dir.parent.parent / \"__init__.py\",\n        version_dir.parent.parent.parent / \"__init__.py\"\n    ]\n    \n    for init_file in init_files:\n        if not init_file.exists():\n            try:\n                init_file.parent.mkdir(parents=True, exist_ok=True)\n                init_file.write_text(\"\")\n                print(f\"Created {init_file}\")\n            except Exception as e:\n                print(f\"Could not create {init_file}: {e}\")\n    \n    # Fix the broken import in modeling_dots_ocr.py\n    modeling_file = version_dir / \"modeling_dots_ocr.py\"\n    if modeling_file.exists():\n        try:\n            content = modeling_file.read_text()\n            \n            # Replace the problematic relative import\n            old_import = \"from .modeling_dots_vision import DotsVisionTransformer\"\n            new_import = \"\"\"\ntry:\n    from .modeling_dots_vision import DotsVisionTransformer\nexcept ImportError:\n    # Fallback for broken relative imports\n    import importlib.util\n    import sys\n    \n    vision_file = Path(__file__).parent / \"modeling_dots_vision.py\"\n    spec = importlib.util.spec_from_file_location(\"modeling_dots_vision\", vision_file)\n    vision_module = importlib.util.module_from_spec(spec)\n    sys.modules[\"modeling_dots_vision\"] = vision_module\n    spec.loader.exec_module(vision_module)\n    DotsVisionTransformer = vision_module.DotsVisionTransformer\n\"\"\"\n            \n            if old_import in content:\n                content = content.replace(old_import, new_import)\n                modeling_file.write_text(content)\n                print(\"Fixed import in modeling_dots_ocr.py\")\n            else:\n                print(\"Import already fixed or not found\")\n                \n        except Exception as e:\n            print(f\"Could not fix modeling file: {e}\")\n    \n    return True\n\n# Apply the fix\nif fix_dots_ocr_imports():\n    print(\"Import fix applied successfully!\")\n    \n    # Clear any cached modules that might have the old broken imports\n    modules_to_clear = [k for k in list(sys.modules.keys()) if 'dots' in k.lower() or 'transformers_modules' in k]\n    for module in modules_to_clear:\n        if module in sys.modules:\n            del sys.modules[module]\n    \n    print(f\"Cleared {len(modules_to_clear)} cached modules\")\n    \n    # Now try to load the model\n    try:\n        print(\"Attempting to load model with fixed imports...\")\n        \n        model = AutoModelForCausalLM.from_pretrained(\n            model_id,\n            torch_dtype=torch.bfloat16,\n            device_map=\"auto\",\n            trust_remote_code=True,\n            token=HF_TOKEN,\n            low_cpu_mem_usage=True\n        )\n        \n        print(\"✅ Model loaded successfully!\")\n        print(f\"Model device: {model.device}\")\n        print(f\"Model dtype: {model.dtype}\")\n        \n    except Exception as e:\n        print(f\"❌ Model loading still failed: {e}\")\n        print(\"\\nTrying alternative approach...\")\n        \n        # Alternative: Force download and try again\n        try:\n            from huggingface_hub import snapshot_download\n            snapshot_download(\n                repo_id=model_id,\n                force_download=True,\n                token=HF_TOKEN\n            )\n            print(\"Re-downloaded model files\")\n            \n            # Try loading again\n            model = AutoModelForCausalLM.from_pretrained(\n                model_id,\n                torch_dtype=torch.bfloat16,\n                device_map=\"auto\",\n                trust_remote_code=True,\n                token=HF_TOKEN,\n                force_download=True\n            )\n            print(\"✅ Model loaded after re-download!\")\n            \n        except Exception as e2:\n            print(f\"❌ All methods failed: {e2}\")\n            print(\"Please restart kernel and try again\")\n            \nelse:\n    print(\"Could not apply import fix\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T11:04:15.227648Z","iopub.execute_input":"2025-08-06T11:04:15.228428Z","iopub.status.idle":"2025-08-06T11:04:15.241681Z","shell.execute_reply.started":"2025-08-06T11:04:15.228399Z","shell.execute_reply":"2025-08-06T11:04:15.240921Z"}},"outputs":[{"name":"stdout","text":"Fixing dots.ocr module imports...\ndots.ocr module directory not found\nCould not apply import fix\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# COMPLETE SOLUTION: Download first, then fix imports\nimport sys\nimport os\nfrom pathlib import Path\nfrom transformers.utils import TRANSFORMERS_CACHE\nfrom huggingface_hub import snapshot_download\n\ndef download_and_fix_dots_ocr():\n    \"\"\"\n    Download dots.ocr model files and fix the import issues\n    \"\"\"\n    print(\"Step 1: Downloading dots.ocr model files...\")\n    \n    try:\n        # Force download all model files\n        local_dir = snapshot_download(\n            repo_id=\"rednote-hilab/dots.ocr\",\n            token=HF_TOKEN,\n            force_download=True,\n            resume_download=False\n        )\n        print(f\"✅ Downloaded model files to: {local_dir}\")\n    except Exception as e:\n        print(f\"❌ Download failed: {e}\")\n        return False\n    \n    print(\"\\nStep 2: Locating and fixing module imports...\")\n    \n    # Now find the downloaded modules\n    cache_dir = Path(TRANSFORMERS_CACHE)\n    dots_module_dir = cache_dir / \"modules\" / \"transformers_modules\" / \"rednote-hilab\" / \"dots.ocr\"\n    \n    if not dots_module_dir.exists():\n        print(\"Still no dots.ocr module directory found after download\")\n        return False\n    \n    # Find version directory\n    version_dirs = [d for d in dots_module_dir.iterdir() if d.is_dir()]\n    if not version_dirs:\n        print(\"No version directories found\")\n        return False\n    \n    version_dir = version_dirs[0]\n    print(f\"Found version directory: {version_dir}\")\n    \n    # Add to Python path\n    if str(version_dir) not in sys.path:\n        sys.path.insert(0, str(version_dir))\n        print(f\"Added to Python path: {version_dir}\")\n    \n    # Create __init__.py files\n    init_paths = [\n        version_dir / \"__init__.py\",\n        version_dir.parent / \"__init__.py\", \n        version_dir.parent.parent / \"__init__.py\",\n        cache_dir / \"modules\" / \"__init__.py\",\n        cache_dir / \"modules\" / \"transformers_modules\" / \"__init__.py\",\n        cache_dir / \"modules\" / \"transformers_modules\" / \"rednote-hilab\" / \"__init__.py\"\n    ]\n    \n    for init_path in init_paths:\n        try:\n            init_path.parent.mkdir(parents=True, exist_ok=True)\n            if not init_path.exists():\n                init_path.write_text(\"\")\n                print(f\"Created: {init_path}\")\n        except Exception as e:\n            print(f\"Could not create {init_path}: {e}\")\n    \n    # Fix the problematic import in modeling_dots_ocr.py\n    modeling_file = version_dir / \"modeling_dots_ocr.py\"\n    if modeling_file.exists():\n        print(\"Fixing modeling_dots_ocr.py imports...\")\n        try:\n            content = modeling_file.read_text()\n            \n            # Replace the broken import line\n            old_line = \"from .modeling_dots_vision import DotsVisionTransformer\"\n            \n            new_lines = '''# Fixed import for DotsVisionTransformer\nimport sys\nfrom pathlib import Path\ntry:\n    from .modeling_dots_vision import DotsVisionTransformer\nexcept ImportError:\n    # Manual import fallback\n    current_dir = Path(__file__).parent\n    vision_file = current_dir / \"modeling_dots_vision.py\"\n    if vision_file.exists():\n        import importlib.util\n        spec = importlib.util.spec_from_file_location(\"modeling_dots_vision\", vision_file)\n        vision_module = importlib.util.module_from_spec(spec)\n        spec.loader.exec_module(vision_module)\n        DotsVisionTransformer = vision_module.DotsVisionTransformer\n    else:\n        raise ImportError(\"Could not find modeling_dots_vision.py\")'''\n            \n            if old_line in content:\n                content = content.replace(old_line, new_lines)\n                modeling_file.write_text(content)\n                print(\"✅ Fixed import in modeling_dots_ocr.py\")\n            else:\n                print(\"Import line not found or already fixed\")\n                \n        except Exception as e:\n            print(f\"❌ Could not fix modeling file: {e}\")\n            return False\n    else:\n        print(\"❌ modeling_dots_ocr.py not found\")\n        return False\n    \n    return True\n\n# Execute the fix\nprint(\"Starting complete dots.ocr fix process...\")\nprint(\"=\" * 50)\n\nif download_and_fix_dots_ocr():\n    print(\"\\n\" + \"=\" * 50)\n    print(\"✅ Download and fix completed successfully!\")\n    \n    # Clear any cached broken modules\n    modules_to_clear = [k for k in list(sys.modules.keys()) \n                       if any(x in k.lower() for x in ['dots', 'transformers_modules'])]\n    for module in modules_to_clear:\n        if module in sys.modules:\n            del sys.modules[module]\n    print(f\"Cleared {len(modules_to_clear)} cached modules\")\n    \n    print(\"\\nStep 3: Attempting to load the model...\")\n    try:\n        model = AutoModelForCausalLM.from_pretrained(\n            model_id,\n            torch_dtype=torch.bfloat16,\n            device_map=\"auto\", \n            trust_remote_code=True,\n            token=HF_TOKEN,\n            low_cpu_mem_usage=True,\n            local_files_only=False  # Allow using downloaded files\n        )\n        \n        print(\"🎉 SUCCESS! Model loaded successfully!\")\n        print(f\"Model device: {model.device}\")\n        print(f\"Model dtype: {model.dtype}\")\n        \n    except Exception as e:\n        print(f\"❌ Model loading failed even after fix: {e}\")\n        \n        # Last resort: try with different parameters\n        print(\"\\nTrying with alternative loading parameters...\")\n        try:\n            model = AutoModelForCausalLM.from_pretrained(\n                model_id,\n                torch_dtype=torch.float16,  # Different dtype\n                device_map=\"cpu\",  # Force CPU first\n                trust_remote_code=True,\n                token=HF_TOKEN\n            )\n            print(\"✅ Model loaded on CPU!\")\n            \n            # Move to GPU if available\n            if torch.cuda.is_available():\n                model = model.to(\"cuda\")\n                print(\"✅ Moved model to GPU!\")\n                \n        except Exception as e2:\n            print(f\"❌ All loading attempts failed: {e2}\")\n            print(\"\\n🔄 Please restart the kernel and try again.\")\n            \nelse:\n    print(\"❌ Download and fix process failed\")\n    print(\"Please check your HF_TOKEN and internet connection\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T11:05:09.088569Z","iopub.execute_input":"2025-08-06T11:05:09.088877Z","iopub.status.idle":"2025-08-06T11:05:31.188996Z","shell.execute_reply.started":"2025-08-06T11:05:09.088854Z","shell.execute_reply":"2025-08-06T11:05:31.188088Z"}},"outputs":[{"name":"stdout","text":"Starting complete dots.ocr fix process...\n==================================================\nStep 1: Downloading dots.ocr model files...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99a43978a9ed47d3b1d196b130c8f26a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a20f7006291342e5a8514befcb3e9621"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_dots.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f46d89a945bb450cadc6cef98ee53906"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c0f86cb4aa240218bd2ee49e835e4d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.29G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb440040567a46e99fd0c1698fe08f19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.79G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"239f6db7f8634b6a80e07f3c85548d0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e58a982b3fe34c79acc9c63f1c01fa65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":".gitattributes: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ac719da97bf4d2c94fd871f99c3e39e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1647ef93d1f945a9864499fc267c1d16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modeling_dots_ocr.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"960846a1cd2c492bb5e7548dd4d8fd14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23e5e6ee0148474096398eee162d86e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modeling_dots_vision.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb7646a89c7249919043e60c35be779e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/494 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa35010fc84c49e7a38b4c9e1dc93c9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modeling_dots_ocr_vllm.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76c85864d6814da1ba79deec4c7481b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d95e546714e74f89a2cc4fa207edcf1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4083d101432148c181f26678f9aa7f62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b922fec50ee4ff381e3764967cd034e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d084269166604da5a4cdb20f2b2c5185"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ae43276e7434bb2b070a4e21b98bf7e"}},"metadata":{}},{"name":"stdout","text":"✅ Downloaded model files to: /root/.cache/huggingface/hub/models--rednote-hilab--dots.ocr/snapshots/42f41787f2475c0894d75a9e30e49cc1a6df519f\n\nStep 2: Locating and fixing module imports...\nStill no dots.ocr module directory found after download\n❌ Download and fix process failed\nPlease check your HF_TOKEN and internet connection\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# CORRECT APPROACH: Trigger module creation then fix\nimport sys\nimport os\nfrom pathlib import Path\nfrom transformers.utils import TRANSFORMERS_CACHE\n\ndef trigger_and_fix_dots_ocr():\n    \"\"\"\n    Trigger the module creation by attempting to load, then fix the imports\n    \"\"\"\n    print(\"Step 1: Triggering module creation...\")\n    \n    # First, try to load the model to trigger module creation\n    # This will fail but will create the modules directory\n    try:\n        model = AutoModelForCausalLM.from_pretrained(\n            model_id,\n            torch_dtype=torch.bfloat16,\n            device_map=\"auto\",\n            trust_remote_code=True,\n            token=HF_TOKEN\n        )\n        print(\"Model loaded successfully on first try!\")\n        return True, model\n    except Exception as e:\n        print(f\"Expected failure (this creates the modules): {e}\")\n    \n    print(\"\\nStep 2: Looking for created modules...\")\n    \n    # Now the modules should exist\n    cache_dir = Path(TRANSFORMERS_CACHE)\n    dots_module_dir = cache_dir / \"modules\" / \"transformers_modules\" / \"rednote-hilab\" / \"dots.ocr\"\n    \n    if not dots_module_dir.exists():\n        print(f\"Module directory still not found at: {dots_module_dir}\")\n        print(\"Let's check what was created...\")\n        \n        # Debug: show what's in the cache\n        modules_dir = cache_dir / \"modules\"\n        if modules_dir.exists():\n            print(f\"Contents of {modules_dir}:\")\n            for item in modules_dir.rglob(\"*\"):\n                if \"dots\" in str(item).lower():\n                    print(f\"  Found: {item}\")\n        \n        return False, None\n    \n    # Find the version directory\n    version_dirs = [d for d in dots_module_dir.iterdir() if d.is_dir()]\n    if not version_dirs:\n        print(\"No version directories found\")\n        return False, None\n    \n    version_dir = version_dirs[0]\n    print(f\"Found version directory: {version_dir}\")\n    \n    print(\"\\nStep 3: Fixing the import issue...\")\n    \n    # Add to Python path\n    if str(version_dir) not in sys.path:\n        sys.path.insert(0, str(version_dir))\n        print(f\"Added to Python path: {version_dir}\")\n    \n    # Create __init__.py files for proper module structure\n    init_files = [\n        cache_dir / \"modules\" / \"__init__.py\",\n        cache_dir / \"modules\" / \"transformers_modules\" / \"__init__.py\", \n        cache_dir / \"modules\" / \"transformers_modules\" / \"rednote-hilab\" / \"__init__.py\",\n        dots_module_dir / \"__init__.py\",\n        version_dir / \"__init__.py\"\n    ]\n    \n    for init_file in init_files:\n        try:\n            init_file.parent.mkdir(parents=True, exist_ok=True)\n            if not init_file.exists():\n                init_file.write_text(\"\")\n                print(f\"Created: {init_file.name}\")\n        except Exception as e:\n            print(f\"Could not create {init_file}: {e}\")\n    \n    # Fix the broken import in modeling_dots_ocr.py\n    modeling_file = version_dir / \"modeling_dots_ocr.py\"\n    \n    if not modeling_file.exists():\n        print(f\"❌ modeling_dots_ocr.py not found at {modeling_file}\")\n        return False, None\n    \n    print(\"Patching modeling_dots_ocr.py...\")\n    \n    try:\n        content = modeling_file.read_text()\n        \n        # Check if already patched\n        if \"# PATCHED IMPORT\" in content:\n            print(\"File already patched\")\n        else:\n            # Replace the problematic import\n            old_import = \"from .modeling_dots_vision import DotsVisionTransformer\"\n            \n            patched_import = \"\"\"# PATCHED IMPORT - Fixed relative import issue\nimport sys\nfrom pathlib import Path\n\ntry:\n    from .modeling_dots_vision import DotsVisionTransformer\nexcept (ImportError, ModuleNotFoundError):\n    # Fallback: direct file import\n    current_file = Path(__file__)\n    vision_file = current_file.parent / \"modeling_dots_vision.py\"\n    \n    if vision_file.exists():\n        import importlib.util\n        spec = importlib.util.spec_from_file_location(\"modeling_dots_vision\", vision_file)\n        vision_module = importlib.util.module_from_spec(spec)\n        sys.modules[f\"{__name__}.modeling_dots_vision\"] = vision_module\n        spec.loader.exec_module(vision_module)\n        DotsVisionTransformer = vision_module.DotsVisionTransformer\n        print(f\"Successfully imported DotsVisionTransformer via fallback\")\n    else:\n        raise ImportError(f\"Could not find modeling_dots_vision.py at {vision_file}\")\"\"\"\n            \n            if old_import in content:\n                content = content.replace(old_import, patched_import)\n                modeling_file.write_text(content)\n                print(\"✅ Successfully patched modeling_dots_ocr.py\")\n            else:\n                print(\"⚠️ Import line not found - file may have different structure\")\n                print(\"First few lines of the file:\")\n                print(\"\\n\".join(content.split(\"\\n\")[:15]))\n    \n    except Exception as e:\n        print(f\"❌ Could not patch file: {e}\")\n        return False, None\n    \n    # Clear any cached broken imports\n    modules_to_clear = [k for k in list(sys.modules.keys()) \n                       if any(x in k for x in ['dots', 'transformers_modules'])]\n    for module in modules_to_clear:\n        if module in sys.modules:\n            del sys.modules[module]\n    print(f\"Cleared {len(modules_to_clear)} cached modules\")\n    \n    print(\"\\nStep 4: Attempting to load model with fixed imports...\")\n    \n    try:\n        model = AutoModelForCausalLM.from_pretrained(\n            model_id,\n            torch_dtype=torch.bfloat16,\n            device_map=\"auto\",\n            trust_remote_code=True,\n            token=HF_TOKEN,\n            low_cpu_mem_usage=True\n        )\n        \n        print(\"🎉 SUCCESS! Model loaded with patched imports!\")\n        return True, model\n        \n    except Exception as e:\n        print(f\"❌ Model loading still failed: {e}\")\n        \n        # Try one more approach: force local files only\n        try:\n            print(\"Trying with local_files_only=True...\")\n            model = AutoModelForCausalLM.from_pretrained(\n                model_id,\n                torch_dtype=torch.bfloat16,\n                device_map=\"auto\",\n                trust_remote_code=True,\n                token=HF_TOKEN,\n                local_files_only=True\n            )\n            print(\"✅ Model loaded with local files!\")\n            return True, model\n        except Exception as e2:\n            print(f\"❌ Final attempt failed: {e2}\")\n            return False, None\n\n# Execute the complete fix\nprint(\"=\" * 60)\nprint(\"COMPLETE DOTS.OCR LOADING AND FIXING PROCESS\")\nprint(\"=\" * 60)\n\nsuccess, model = trigger_and_fix_dots_ocr()\n\nif success:\n    print(f\"\\n🎉 FINAL SUCCESS!\")\n    print(f\"Model device: {model.device}\")\n    print(f\"Model dtype: {model.dtype}\")\n    print(f\"Model loaded and ready for Bengali OCR testing!\")\nelse:\n    print(f\"\\n❌ Process failed. Let's try a manual approach...\")\n    \n    # Manual debug approach\n    print(\"Checking transformers cache manually...\")\n    cache_dir = Path(TRANSFORMERS_CACHE)\n    print(f\"Cache directory: {cache_dir}\")\n    \n    if cache_dir.exists():\n        for item in cache_dir.rglob(\"*dots*\"):\n            print(f\"Found dots-related: {item}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T11:06:40.964148Z","iopub.execute_input":"2025-08-06T11:06:40.964920Z","iopub.status.idle":"2025-08-06T11:06:41.165328Z","shell.execute_reply.started":"2025-08-06T11:06:40.964891Z","shell.execute_reply":"2025-08-06T11:06:41.164678Z"}},"outputs":[{"name":"stdout","text":"============================================================\nCOMPLETE DOTS.OCR LOADING AND FIXING PROCESS\n============================================================\nStep 1: Triggering module creation...\nExpected failure (this creates the modules): No module named 'transformers_modules.rednote-hilab.dots'\n\nStep 2: Looking for created modules...\nModule directory still not found at: /root/.cache/huggingface/hub/modules/transformers_modules/rednote-hilab/dots.ocr\nLet's check what was created...\n\n❌ Process failed. Let's try a manual approach...\nChecking transformers cache manually...\nCache directory: /root/.cache/huggingface/hub\nFound dots-related: /root/.cache/huggingface/hub/models--rednote-hilab--dots.ocr\nFound dots-related: /root/.cache/huggingface/hub/models--rednote-hilab--dots.ocr/snapshots/42f41787f2475c0894d75a9e30e49cc1a6df519f/configuration_dots.py\nFound dots-related: /root/.cache/huggingface/hub/models--rednote-hilab--dots.ocr/snapshots/42f41787f2475c0894d75a9e30e49cc1a6df519f/modeling_dots_vision.py\nFound dots-related: /root/.cache/huggingface/hub/models--rednote-hilab--dots.ocr/snapshots/42f41787f2475c0894d75a9e30e49cc1a6df519f/modeling_dots_ocr.py\nFound dots-related: /root/.cache/huggingface/hub/models--rednote-hilab--dots.ocr/snapshots/42f41787f2475c0894d75a9e30e49cc1a6df519f/modeling_dots_ocr_vllm.py\nFound dots-related: /root/.cache/huggingface/hub/.locks/models--rednote-hilab--dots.ocr\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# DIRECT FIX: Work with the actual downloaded files\nimport sys\nimport shutil\nfrom pathlib import Path\nfrom transformers.utils import TRANSFORMERS_CACHE\n\ndef direct_fix_dots_ocr():\n    \"\"\"\n    Directly fix the downloaded files and create proper module structure\n    \"\"\"\n    print(\"Direct fix approach using actual downloaded files...\")\n    \n    # Locate the actual downloaded files\n    hub_cache = Path(\"/root/.cache/huggingface/hub\")\n    model_dir = hub_cache / \"models--rednote-hilab--dots.ocr\"\n    \n    # Find the snapshot directory\n    snapshots_dir = model_dir / \"snapshots\"\n    if not snapshots_dir.exists():\n        print(\"❌ Snapshots directory not found\")\n        return False\n    \n    # Get the latest snapshot\n    snapshot_dirs = [d for d in snapshots_dir.iterdir() if d.is_dir()]\n    if not snapshot_dirs:\n        print(\"❌ No snapshot directories found\")\n        return False\n    \n    snapshot_dir = snapshot_dirs[0]  # Use the first (latest) snapshot\n    print(f\"✅ Found snapshot: {snapshot_dir}\")\n    \n    # Check for the problematic files\n    modeling_ocr_file = snapshot_dir / \"modeling_dots_ocr.py\"\n    modeling_vision_file = snapshot_dir / \"modeling_dots_vision.py\"\n    \n    if not modeling_ocr_file.exists():\n        print(\"❌ modeling_dots_ocr.py not found\")\n        return False\n    \n    if not modeling_vision_file.exists():\n        print(\"❌ modeling_dots_vision.py not found\")  \n        return False\n    \n    print(\"✅ Found both modeling files\")\n    \n    # Add the snapshot directory to Python path\n    if str(snapshot_dir) not in sys.path:\n        sys.path.insert(0, str(snapshot_dir))\n        print(f\"✅ Added to Python path: {snapshot_dir}\")\n    \n    # Create the transformers_modules directory structure that transformers expects\n    transformers_cache = Path(TRANSFORMERS_CACHE)\n    modules_dir = transformers_cache / \"modules\" / \"transformers_modules\" / \"rednote-hilab\" / \"dots.ocr\"\n    \n    # Create a version directory (use the snapshot hash)\n    version_dir = modules_dir / snapshot_dir.name\n    version_dir.mkdir(parents=True, exist_ok=True)\n    \n    print(f\"✅ Created modules directory: {version_dir}\")\n    \n    # Copy the files to the expected location\n    files_to_copy = [\n        \"modeling_dots_ocr.py\",\n        \"modeling_dots_vision.py\", \n        \"configuration_dots.py\"\n    ]\n    \n    for file_name in files_to_copy:\n        source = snapshot_dir / file_name\n        dest = version_dir / file_name\n        if source.exists():\n            shutil.copy2(source, dest)\n            print(f\"✅ Copied {file_name}\")\n        else:\n            print(f\"⚠️ {file_name} not found\")\n    \n    # Create __init__.py files\n    init_files = [\n        transformers_cache / \"modules\" / \"__init__.py\",\n        transformers_cache / \"modules\" / \"transformers_modules\" / \"__init__.py\",\n        transformers_cache / \"modules\" / \"transformers_modules\" / \"rednote-hilab\" / \"__init__.py\",\n        modules_dir / \"__init__.py\",\n        version_dir / \"__init__.py\"\n    ]\n    \n    for init_file in init_files:\n        if not init_file.exists():\n            init_file.write_text(\"\")\n            print(f\"✅ Created {init_file.name}\")\n    \n    # Now fix the import issue in the copied file\n    modeling_file = version_dir / \"modeling_dots_ocr.py\"\n    \n    print(\"🔧 Fixing import in modeling_dots_ocr.py...\")\n    \n    try:\n        content = modeling_file.read_text()\n        \n        # Find and replace the problematic import\n        old_import = \"from .modeling_dots_vision import DotsVisionTransformer\"\n        \n        # Create a more robust import\n        new_import = \"\"\"# FIXED IMPORT\nimport sys\nfrom pathlib import Path\nimport importlib.util\n\ndef import_dots_vision():\n    # Try relative import first\n    try:\n        from .modeling_dots_vision import DotsVisionTransformer\n        return DotsVisionTransformer\n    except ImportError:\n        pass\n    \n    # Try absolute import from current directory\n    try:\n        current_dir = Path(__file__).parent\n        vision_file = current_dir / \"modeling_dots_vision.py\"\n        \n        if vision_file.exists():\n            spec = importlib.util.spec_from_file_location(\"modeling_dots_vision\", vision_file)\n            vision_module = importlib.util.module_from_spec(spec)\n            spec.loader.exec_module(vision_module)\n            return vision_module.DotsVisionTransformer\n    except Exception as e:\n        print(f\"Import fallback failed: {e}\")\n    \n    # Last resort: try from sys.path\n    try:\n        import modeling_dots_vision\n        return modeling_dots_vision.DotsVisionTransformer\n    except ImportError:\n        pass\n    \n    raise ImportError(\"Could not import DotsVisionTransformer from any method\")\n\nDotsVisionTransformer = import_dots_vision()\"\"\"\n        \n        if old_import in content:\n            content = content.replace(old_import, new_import)\n            modeling_file.write_text(content)\n            print(\"✅ Successfully fixed the import!\")\n        else:\n            print(\"⚠️ Import line not found, checking file structure...\")\n            lines = content.split('\\n')[:10]\n            for i, line in enumerate(lines):\n                print(f\"{i+1}: {line}\")\n    \n    except Exception as e:\n        print(f\"❌ Could not fix import: {e}\")\n        return False\n    \n    # Clear any cached modules\n    modules_to_clear = [k for k in list(sys.modules.keys()) \n                       if any(x in k for x in ['dots', 'transformers_modules'])]\n    for module in modules_to_clear:\n        if module in sys.modules:\n            del sys.modules[module]\n    \n    print(f\"✅ Cleared {len(modules_to_clear)} cached modules\")\n    \n    return True\n\n# Execute the direct fix\nprint(\"🚀 Starting direct fix process...\")\nprint(\"=\" * 50)\n\nif direct_fix_dots_ocr():\n    print(\"\\n✅ Direct fix completed! Now attempting to load model...\")\n    \n    try:\n        # Clear any remaining cached imports\n        import gc\n        gc.collect()\n        \n        # Try loading the model\n        model = AutoModelForCausalLM.from_pretrained(\n            model_id,\n            torch_dtype=torch.bfloat16,\n            device_map=\"auto\",\n            trust_remote_code=True,\n            token=HF_TOKEN,\n            low_cpu_mem_usage=True\n        )\n        \n        print(\"🎉 HUGE SUCCESS! Model loaded successfully!\")\n        print(f\"Model device: {model.device}\")\n        print(f\"Model dtype: {model.dtype}\")\n        print(f\"Model is ready for Bengali OCR testing! 🎯\")\n        \n    except Exception as e:\n        print(f\"❌ Model loading failed: {e}\")\n        \n        # One more try with different parameters\n        print(\"\\n🔄 Trying alternative loading parameters...\")\n        try:\n            model = AutoModelForCausalLM.from_pretrained(\n                model_id,\n                torch_dtype=torch.float16,\n                device_map=\"cpu\",\n                trust_remote_code=True,\n                token=HF_TOKEN\n            )\n            print(\"✅ Model loaded on CPU!\")\n            \n            # Move to GPU if available\n            if torch.cuda.is_available():\n                try:\n                    model = model.to(\"cuda\")\n                    print(\"✅ Successfully moved to GPU!\")\n                except:\n                    print(\"⚠️ Staying on CPU due to memory constraints\")\n                    \n        except Exception as e2:\n            print(f\"❌ All attempts failed: {e2}\")\n            print(\"\\n💡 Try restarting the kernel and running this fix again\")\n            \nelse:\n    print(\"❌ Direct fix failed\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T11:07:41.459099Z","iopub.execute_input":"2025-08-06T11:07:41.459640Z","iopub.status.idle":"2025-08-06T11:07:42.188622Z","shell.execute_reply.started":"2025-08-06T11:07:41.459617Z","shell.execute_reply":"2025-08-06T11:07:42.187938Z"}},"outputs":[{"name":"stdout","text":"🚀 Starting direct fix process...\n==================================================\nDirect fix approach using actual downloaded files...\n✅ Found snapshot: /root/.cache/huggingface/hub/models--rednote-hilab--dots.ocr/snapshots/42f41787f2475c0894d75a9e30e49cc1a6df519f\n✅ Found both modeling files\n✅ Added to Python path: /root/.cache/huggingface/hub/models--rednote-hilab--dots.ocr/snapshots/42f41787f2475c0894d75a9e30e49cc1a6df519f\n✅ Created modules directory: /root/.cache/huggingface/hub/modules/transformers_modules/rednote-hilab/dots.ocr/42f41787f2475c0894d75a9e30e49cc1a6df519f\n✅ Copied modeling_dots_ocr.py\n✅ Copied modeling_dots_vision.py\n✅ Copied configuration_dots.py\n✅ Created __init__.py\n✅ Created __init__.py\n✅ Created __init__.py\n✅ Created __init__.py\n✅ Created __init__.py\n🔧 Fixing import in modeling_dots_ocr.py...\n✅ Successfully fixed the import!\n✅ Cleared 4 cached modules\n\n✅ Direct fix completed! Now attempting to load model...\n❌ Model loading failed: No module named 'transformers_modules.rednote-hilab.dots'\n\n🔄 Trying alternative loading parameters...\n❌ All attempts failed: No module named 'transformers_modules.rednote-hilab.dots'\n\n💡 Try restarting the kernel and running this fix again\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# NUCLEAR OPTION: Direct Python import system patching\nimport sys\nimport importlib.util\nfrom pathlib import Path\n\ndef nuclear_fix_dots_ocr():\n    \"\"\"\n    Directly patch Python's import system to handle the broken module structure\n    \"\"\"\n    print(\"🚀 Nuclear option: Direct import system patching...\")\n    \n    # Get the actual file paths\n    snapshot_dir = Path(\"/root/.cache/huggingface/hub/models--rednote-hilab--dots.ocr/snapshots/42f41787f2475c0894d75a9e30e49cc1a6df519f\")\n    \n    modeling_ocr_file = snapshot_dir / \"modeling_dots_ocr.py\"\n    modeling_vision_file = snapshot_dir / \"modeling_dots_vision.py\"\n    config_file = snapshot_dir / \"configuration_dots.py\"\n    \n    if not all([modeling_ocr_file.exists(), modeling_vision_file.exists(), config_file.exists()]):\n        print(\"❌ Required files not found\")\n        return False\n    \n    print(\"✅ All required files found\")\n    \n    # STEP 1: Manually load and register the modules\n    print(\"📦 Manually loading modules...\")\n    \n    try:\n        # Load configuration_dots module\n        spec = importlib.util.spec_from_file_location(\"configuration_dots\", config_file)\n        config_module = importlib.util.module_from_spec(spec)\n        sys.modules[\"configuration_dots\"] = config_module\n        sys.modules[\"transformers_modules.rednote-hilab.dots.configuration_dots\"] = config_module\n        spec.loader.exec_module(config_module)\n        print(\"✅ Loaded configuration_dots\")\n        \n        # Load modeling_dots_vision module  \n        spec = importlib.util.spec_from_file_location(\"modeling_dots_vision\", modeling_vision_file)\n        vision_module = importlib.util.module_from_spec(spec)\n        sys.modules[\"modeling_dots_vision\"] = vision_module\n        sys.modules[\"transformers_modules.rednote-hilab.dots.modeling_dots_vision\"] = vision_module\n        spec.loader.exec_module(vision_module)\n        print(\"✅ Loaded modeling_dots_vision\")\n        \n        # Create a patched version of modeling_dots_ocr that uses our loaded modules\n        ocr_content = modeling_ocr_file.read_text()\n        \n        # Replace the problematic imports with direct references\n        patched_content = ocr_content.replace(\n            \"from .configuration_dots import DotsVisionConfig, DotsOCRConfig\",\n            \"DotsVisionConfig = sys.modules['configuration_dots'].DotsVisionConfig\\nDotsOCRConfig = sys.modules['configuration_dots'].DotsOCRConfig\"\n        ).replace(\n            \"from .modeling_dots_vision import DotsVisionTransformer\", \n            \"DotsVisionTransformer = sys.modules['modeling_dots_vision'].DotsVisionTransformer\"\n        )\n        \n        # Add sys import at the top\n        if \"import sys\" not in patched_content:\n            patched_content = \"import sys\\n\" + patched_content\n        \n        # Load the patched OCR module\n        spec = importlib.util.spec_from_loader(\"modeling_dots_ocr\", loader=None)\n        ocr_module = importlib.util.module_from_spec(spec)\n        \n        # Execute the patched content in the module's namespace\n        exec(patched_content, ocr_module.__dict__)\n        \n        # Register the module in all the places transformers might look\n        sys.modules[\"modeling_dots_ocr\"] = ocr_module\n        sys.modules[\"transformers_modules.rednote-hilab.dots.modeling_dots_ocr\"] = ocr_module\n        sys.modules[\"transformers_modules.rednote-hilab.dots\"] = ocr_module  # This is the key one!\n        \n        print(\"✅ Loaded and patched modeling_dots_ocr\")\n        \n        # Create a fake package structure\n        class FakeModule:\n            def __init__(self, name):\n                self.__name__ = name\n                self.__path__ = []\n        \n        # Create the missing package hierarchy\n        sys.modules[\"transformers_modules\"] = FakeModule(\"transformers_modules\")\n        sys.modules[\"transformers_modules.rednote-hilab\"] = FakeModule(\"transformers_modules.rednote-hilab\")\n        \n        print(\"✅ Created fake package structure\")\n        \n    except Exception as e:\n        print(f\"❌ Module loading failed: {e}\")\n        import traceback\n        traceback.print_exc()\n        return False\n    \n    return True\n\n# Execute nuclear fix\nprint(\"💥 NUCLEAR OPTION ACTIVATED\")\nprint(\"=\" * 50)\n\nif nuclear_fix_dots_ocr():\n    print(\"\\n✅ Nuclear fix completed! Testing model loading...\")\n    \n    try:\n        # Force clear everything and try again\n        import gc\n        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n        gc.collect()\n        \n        print(\"🔄 Attempting model load with nuclear fixes...\")\n        \n        model = AutoModelForCausalLM.from_pretrained(\n            model_id,\n            torch_dtype=torch.bfloat16,\n            device_map=\"auto\",\n            trust_remote_code=True,\n            token=HF_TOKEN,\n            low_cpu_mem_usage=True\n        )\n        \n        print(\"🎉🎉🎉 NUCLEAR SUCCESS! MODEL LOADED! 🎉🎉🎉\")\n        print(f\"Model device: {model.device}\")\n        print(f\"Model dtype: {model.dtype}\")\n        print(\"Ready for Bengali OCR testing! 🚀\")\n        \n    except Exception as e:\n        print(f\"❌ Even nuclear option failed: {e}\")\n        print(f\"Error type: {type(e).__name__}\")\n        \n        # Last desperate attempt: try to see what transformers is actually looking for\n        print(\"\\n🔍 Debugging what transformers is actually trying to import...\")\n        try:\n            import transformers.dynamic_module_utils as dmu\n            print(\"Available sys.modules with 'dots':\")\n            for key in sys.modules:\n                if 'dots' in key.lower():\n                    print(f\"  - {key}: {sys.modules[key]}\")\n                    \n            print(\"\\nAvailable sys.modules with 'transformers_modules':\")\n            for key in sys.modules:\n                if 'transformers_modules' in key:\n                    print(f\"  - {key}: {sys.modules[key]}\")\n                    \n        except Exception as debug_e:\n            print(f\"Debug failed: {debug_e}\")\n        \n        # Final attempt with manual class injection\n        print(\"\\n🩹 Final attempt: Manual class injection...\")\n        try:\n            # Get the actual class from our loaded module\n            ocr_module = sys.modules.get(\"modeling_dots_ocr\")\n            if ocr_module and hasattr(ocr_module, 'DotsOCRForConditionalGeneration'):\n                DotsOCRClass = ocr_module.DotsOCRForConditionalGeneration\n                \n                # Manually inject into transformers\n                from transformers import AutoModelForCausalLM\n                AutoModelForCausalLM._model_mapping._extra_content[\"DotsOCRForConditionalGeneration\"] = DotsOCRClass\n                \n                print(\"✅ Manually injected model class\")\n                \n                # Try loading with the injected class\n                model = DotsOCRClass.from_pretrained(\n                    model_id,\n                    torch_dtype=torch.bfloat16,\n                    device_map=\"auto\",\n                    token=HF_TOKEN\n                )\n                \n                print(\"🎉 SUCCESS WITH MANUAL INJECTION!\")\n                print(f\"Model: {type(model)}\")\n                \n            else:\n                print(\"❌ Could not find DotsOCRForConditionalGeneration class\")\n                \n        except Exception as final_e:\n            print(f\"❌ Manual injection failed: {final_e}\")\n            print(\"\\n💀 All methods exhausted. This model has severe import issues.\")\n            print(\"🔄 RESTART KERNEL and try a different approach or different model.\")\n\nelse:\n    print(\"❌ Nuclear fix failed to load modules\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T11:09:04.290340Z","iopub.execute_input":"2025-08-06T11:09:04.290640Z","iopub.status.idle":"2025-08-06T11:09:04.312676Z","shell.execute_reply.started":"2025-08-06T11:09:04.290619Z","shell.execute_reply":"2025-08-06T11:09:04.311794Z"}},"outputs":[{"name":"stdout","text":"💥 NUCLEAR OPTION ACTIVATED\n==================================================\n🚀 Nuclear option: Direct import system patching...\n✅ All required files found\n📦 Manually loading modules...\n✅ Loaded configuration_dots\n❌ Module loading failed: attempted relative import with no known parent package\n❌ Nuclear fix failed to load modules\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_224/979877581.py\", line 42, in nuclear_fix_dots_ocr\n    spec.loader.exec_module(vision_module)\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/root/.cache/huggingface/hub/models--rednote-hilab--dots.ocr/snapshots/42f41787f2475c0894d75a9e30e49cc1a6df519f/modeling_dots_vision.py\", line 10, in <module>\n    from .configuration_dots import DotsVisionConfig\nImportError: attempted relative import with no known parent package\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ULTIMATE FIX: Patch file contents before loading\nimport sys\nimport importlib.util\nfrom pathlib import Path\nimport re\n\ndef ultimate_fix_dots_ocr():\n    \"\"\"\n    The ultimate fix: patch all file contents to remove relative imports\n    \"\"\"\n    print(\"🔥 ULTIMATE FIX: Patching all file contents...\")\n    \n    # Get file paths\n    snapshot_dir = Path(\"/root/.cache/huggingface/hub/models--rednote-hilab--dots.ocr/snapshots/42f41787f2475c0894d75a9e30e49cc1a6df519f\")\n    \n    files = {\n        \"config\": snapshot_dir / \"configuration_dots.py\",\n        \"vision\": snapshot_dir / \"modeling_dots_vision.py\", \n        \"ocr\": snapshot_dir / \"modeling_dots_ocr.py\"\n    }\n    \n    # Check all files exist\n    for name, path in files.items():\n        if not path.exists():\n            print(f\"❌ {name} file not found: {path}\")\n            return False\n    \n    print(\"✅ All files found\")\n    \n    # STEP 1: Read and patch all file contents\n    patched_contents = {}\n    \n    try:\n        # Patch configuration_dots.py\n        config_content = files[\"config\"].read_text()\n        # Remove any relative imports (shouldn't have any, but just in case)\n        patched_contents[\"config\"] = config_content\n        print(\"✅ Configuration file ready\")\n        \n        # Patch modeling_dots_vision.py - this is likely where the relative import error comes from\n        vision_content = files[\"vision\"].read_text()\n        \n        # Replace any relative imports with absolute ones or remove them\n        vision_content = re.sub(r'from\\s+\\.[\\w.]*\\s+import', 'import', vision_content)\n        vision_content = re.sub(r'from\\s+\\.', 'from ', vision_content)\n        \n        # Add necessary imports at the top\n        vision_imports = \"\"\"\nimport torch\nimport torch.nn as nn\nfrom transformers import PreTrainedModel\nfrom transformers.modeling_outputs import BaseModelOutput\nfrom transformers.utils import logging\nimport math\nfrom typing import Optional, Tuple, Union\n\"\"\"\n        \n        if \"import torch\" not in vision_content:\n            vision_content = vision_imports + \"\\n\" + vision_content\n        \n        patched_contents[\"vision\"] = vision_content\n        print(\"✅ Vision file patched\")\n        \n        # Patch modeling_dots_ocr.py\n        ocr_content = files[\"ocr\"].read_text()\n        \n        # Replace relative imports with direct references\n        ocr_content = re.sub(r'from\\s+\\.configuration_dots\\s+import\\s+(.*)', \n                           r'# Patched import - will be injected\\n# \\1 will be available directly', \n                           ocr_content)\n        \n        ocr_content = re.sub(r'from\\s+\\.modeling_dots_vision\\s+import\\s+(.*)',\n                           r'# Patched import - will be injected\\n# \\1 will be available directly',\n                           ocr_content)\n        \n        # Add necessary imports\n        ocr_imports = \"\"\"\nimport sys\nimport torch\nimport torch.nn as nn\nfrom transformers import PreTrainedModel, PretrainedConfig\nfrom transformers.modeling_outputs import CausalLMOutputWithPast\nfrom transformers.utils import logging\nfrom typing import Optional, Tuple, Union, List\nimport math\n\"\"\"\n        \n        if \"import torch\" not in ocr_content:\n            ocr_content = ocr_imports + \"\\n\" + ocr_content\n            \n        patched_contents[\"ocr\"] = ocr_content\n        print(\"✅ OCR file patched\")\n        \n    except Exception as e:\n        print(f\"❌ File patching failed: {e}\")\n        return False\n    \n    # STEP 2: Load modules with patched content\n    try:\n        print(\"📦 Loading patched modules...\")\n        \n        # Load config module\n        config_spec = importlib.util.spec_from_loader(\"configuration_dots\", loader=None)\n        config_module = importlib.util.module_from_spec(config_spec)\n        exec(patched_contents[\"config\"], config_module.__dict__)\n        sys.modules[\"configuration_dots\"] = config_module\n        print(\"✅ Config module loaded\")\n        \n        # Load vision module\n        vision_spec = importlib.util.spec_from_loader(\"modeling_dots_vision\", loader=None)\n        vision_module = importlib.util.module_from_spec(vision_spec)\n        exec(patched_contents[\"vision\"], vision_module.__dict__)\n        sys.modules[\"modeling_dots_vision\"] = vision_module\n        print(\"✅ Vision module loaded\")\n        \n        # Inject dependencies into OCR module namespace before loading\n        ocr_namespace = {\n            '__name__': 'modeling_dots_ocr',\n            '__file__': str(files[\"ocr\"]),\n            'DotsVisionTransformer': getattr(vision_module, 'DotsVisionTransformer', None),\n            'DotsVisionConfig': getattr(config_module, 'DotsVisionConfig', None),\n            'DotsOCRConfig': getattr(config_module, 'DotsOCRConfig', None),\n        }\n        \n        # Add any missing classes that might be needed\n        for attr_name in dir(config_module):\n            if not attr_name.startswith('_'):\n                ocr_namespace[attr_name] = getattr(config_module, attr_name)\n                \n        for attr_name in dir(vision_module):\n            if not attr_name.startswith('_'):\n                ocr_namespace[attr_name] = getattr(vision_module, attr_name)\n        \n        # Load OCR module with injected dependencies\n        ocr_spec = importlib.util.spec_from_loader(\"modeling_dots_ocr\", loader=None)\n        ocr_module = importlib.util.module_from_spec(ocr_spec)\n        \n        # Execute with pre-loaded dependencies\n        exec(patched_contents[\"ocr\"], ocr_namespace)\n        \n        # Copy everything back to the module\n        for key, value in ocr_namespace.items():\n            setattr(ocr_module, key, value)\n        \n        sys.modules[\"modeling_dots_ocr\"] = ocr_module\n        print(\"✅ OCR module loaded\")\n        \n        # Register in transformers_modules namespace\n        sys.modules[\"transformers_modules.rednote-hilab.dots.configuration_dots\"] = config_module\n        sys.modules[\"transformers_modules.rednote-hilab.dots.modeling_dots_vision\"] = vision_module  \n        sys.modules[\"transformers_modules.rednote-hilab.dots.modeling_dots_ocr\"] = ocr_module\n        sys.modules[\"transformers_modules.rednote-hilab.dots\"] = ocr_module\n        \n        # Create package hierarchy\n        class FakePackage:\n            def __init__(self, name):\n                self.__name__ = name\n                self.__path__ = []\n                \n        sys.modules[\"transformers_modules\"] = FakePackage(\"transformers_modules\")\n        sys.modules[\"transformers_modules.rednote-hilab\"] = FakePackage(\"transformers_modules.rednote-hilab\")\n        \n        print(\"✅ All modules registered in transformers namespace\")\n        \n    except Exception as e:\n        print(f\"❌ Module loading failed: {e}\")\n        import traceback\n        traceback.print_exc()\n        return False\n    \n    return True\n\n# Execute ultimate fix\nprint(\"🔥🔥🔥 ULTIMATE FIX ACTIVATED 🔥🔥🔥\")\nprint(\"=\" * 60)\n\nif ultimate_fix_dots_ocr():\n    print(\"\\n✅ ULTIMATE FIX COMPLETED!\")\n    print(\"🚀 Attempting model load...\")\n    \n    try:\n        # Clear cache\n        import gc\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n        gc.collect()\n        \n        # Try loading\n        model = AutoModelForCausalLM.from_pretrained(\n            model_id,\n            torch_dtype=torch.bfloat16,\n            device_map=\"auto\", \n            trust_remote_code=True,\n            token=HF_TOKEN,\n            low_cpu_mem_usage=True\n        )\n        \n        print(\"🎉🎉🎉 ULTIMATE SUCCESS! 🎉🎉🎉\")\n        print(f\"Model loaded: {type(model)}\")\n        print(f\"Model device: {model.device}\")\n        print(f\"Model dtype: {model.dtype}\")\n        print(\"🚀 READY FOR BENGALI OCR! 🚀\")\n        \n    except Exception as e:\n        print(f\"❌ Model loading still failed: {e}\")\n        \n        # Check what we actually loaded\n        print(\"\\n🔍 Checking loaded modules...\")\n        ocr_module = sys.modules.get(\"modeling_dots_ocr\")\n        if ocr_module:\n            print(\"Available classes in OCR module:\")\n            for attr in dir(ocr_module):\n                if not attr.startswith('_') and 'OCR' in attr:\n                    print(f\"  - {attr}: {getattr(ocr_module, attr)}\")\n                    \n            # Try direct instantiation\n            if hasattr(ocr_module, 'DotsOCRForConditionalGeneration'):\n                print(\"\\n🎯 Trying direct class instantiation...\")\n                try:\n                    ModelClass = ocr_module.DotsOCRForConditionalGeneration\n                    model = ModelClass.from_pretrained(\n                        model_id,\n                        torch_dtype=torch.bfloat16,\n                        device_map=\"auto\",\n                        token=HF_TOKEN\n                    )\n                    print(\"🎉 DIRECT INSTANTIATION SUCCESS!\")\n                    print(f\"Model: {type(model)}\")\n                except Exception as direct_e:\n                    print(f\"❌ Direct instantiation failed: {direct_e}\")\n        else:\n            print(\"❌ OCR module not found in sys.modules\")\n            \n        print(\"\\n💀 If this still fails, the model is fundamentally broken.\")\n        print(\"🔄 Consider using a different OCR model like microsoft/trocr-base-printed\")\n\nelse:\n    print(\"❌ Ultimate fix failed\")\n    print(\"💀 This model appears to have unfixable import issues\")\n    print(\"🔄 Recommend trying a different model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T11:10:13.024415Z","iopub.execute_input":"2025-08-06T11:10:13.024715Z","iopub.status.idle":"2025-08-06T11:10:13.049115Z","shell.execute_reply.started":"2025-08-06T11:10:13.024694Z","shell.execute_reply":"2025-08-06T11:10:13.048407Z"}},"outputs":[{"name":"stdout","text":"🔥🔥🔥 ULTIMATE FIX ACTIVATED 🔥🔥🔥\n============================================================\n🔥 ULTIMATE FIX: Patching all file contents...\n✅ All files found\n✅ Configuration file ready\n✅ Vision file patched\n✅ OCR file patched\n📦 Loading patched modules...\n✅ Config module loaded\n❌ Module loading failed: No module named 'DotsVisionConfig'\n❌ Ultimate fix failed\n💀 This model appears to have unfixable import issues\n🔄 Recommend trying a different model\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_224/668948942.py\", line 112, in ultimate_fix_dots_ocr\n    exec(patched_contents[\"vision\"], vision_module.__dict__)\n  File \"<string>\", line 10, in <module>\nModuleNotFoundError: No module named 'DotsVisionConfig'\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}